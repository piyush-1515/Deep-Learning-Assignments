{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 22:48:35.885769: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-08 22:48:36.231014: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-08 22:48:36.233937: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/piyush/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-04-08 22:48:36.233953: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-08 22:48:36.949590: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/piyush/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-04-08 22:48:36.949654: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/piyush/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-04-08 22:48:36.949660: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam, SGD, Adagrad, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data, normalizing and flattening it"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading and Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11385 files belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 22:48:38.438750: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/piyush/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-04-08 22:48:38.438771: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-04-08 22:48:38.438787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (piyush-HP-Spectre-x360-Convertible-13-aw2xxx): /proc/driver/nvidia/version does not exist\n",
      "2023-04-08 22:48:38.438995: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3795 files belonging to 5 classes.\n",
      "Found 3795 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = image_dataset_from_directory(\n",
    "    'Group_24/train/',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=1,\n",
    "    image_size=(28, 28),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    color_mode='grayscale',\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "val = image_dataset_from_directory(\n",
    "    'Group_24/val/',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=1,\n",
    "    image_size=(28, 28),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    color_mode='grayscale',\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "test = image_dataset_from_directory(\n",
    "    'Group_24/test/',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=1,\n",
    "    image_size=(28, 28),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    color_mode='grayscale',\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "def normalize(image,label):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image, label\n",
    "\n",
    "train = train.map(normalize)\n",
    "val = val.map(normalize)\n",
    "test = test.map(normalize)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Flattening"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing training tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataset and reshape each image tensor\n",
    "image_tensors = []\n",
    "label_tensors = []\n",
    "for image, labels in train:\n",
    "    num_images = image.shape[0]\n",
    "    image_vectors = tf.reshape(image, [num_images, -1])\n",
    "    image_tensors.append(image_vectors)\n",
    "    label_tensors.append(labels)\n",
    "\n",
    "# Concatenate the image tensors into a single tensor\n",
    "train_vectors = [tf.concat(image_tensors, axis=0), tf.concat(label_tensors, axis=0)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing validation tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataset and reshape each image tensor\n",
    "image_tensors = []\n",
    "label_tensors = []\n",
    "for image, labels in val:\n",
    "    num_images = image.shape[0]\n",
    "    image_vectors = tf.reshape(image, [num_images, -1])\n",
    "    image_tensors.append(image_vectors)\n",
    "    label_tensors.append(labels)\n",
    "\n",
    "# Concatenate the image tensors into a single tensor\n",
    "val_vectors = [tf.concat(image_tensors, axis=0), tf.concat(label_tensors, axis=0)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing testing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataset and reshape each image tensor\n",
    "image_tensors = []\n",
    "label_tensors = []\n",
    "for image, labels in test:\n",
    "    num_images = image.shape[0]\n",
    "    image_vectors = tf.reshape(image, [num_images, -1])\n",
    "    image_tensors.append(image_vectors)\n",
    "    label_tensors.append(labels)\n",
    "\n",
    "# Concatenate the image tensors into a single tensor\n",
    "test_vectors = [tf.concat(image_tensors, axis=0), tf.concat(label_tensors, axis=0)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Hidden layer autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models with different architectures and optimizers\n",
      "1 Hidden Layer : 32 neurons\n",
      "epochs: 386, mse: 0.02199326641857624\n",
      "\n",
      "1 Hidden Layer : 64 neurons\n",
      "epochs: 313, mse: 0.015301888808608055\n",
      "\n",
      "1 Hidden Layer : 128 neurons\n",
      "epochs: 206, mse: 0.0163264200091362\n",
      "\n",
      "1 Hidden Layer : 256 neurons\n",
      "epochs: 199, mse: 0.015806687995791435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initializer = initializers.RandomNormal(mean=0.0, stddev=0.05, seed=42)\n",
    "\n",
    "k=5 # no. of classes\n",
    "model_history = dict()\n",
    "\n",
    "# train different achitectures and optimizers\n",
    "print('Training 1 Hidden Layer autoencoder with different number of neurons in bottleneck layer')\n",
    "for num_neurons in [32, 64, 128, 256]:\n",
    "    print(f'1 Hidden Layer : {num_neurons} neurons')\n",
    "    # define model\n",
    "    model = Sequential([\n",
    "        layers.Dense(784, activation=\"relu\", input_shape=(784,)),\n",
    "        layers.Dense(num_neurons, activation=\"sigmoid\", name=\"hidden\", \n",
    "                        kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "        layers.Dense(784, activation=\"relu\", name=\"output\", \n",
    "                        kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "    ])\n",
    "    \n",
    "    # compile model\n",
    "    loss = tf.keras.losses.MeanSquaredError()\n",
    "    adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "    model.compile(optimizer=adam_optimizer, loss=loss, metrics=['mse'])\n",
    "    \n",
    "    # callbacks\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5),\n",
    "        TensorBoard(log_dir=f'./logdir/Q2/1_hidden_layer_{num_neurons}_neurons/')\n",
    "    ]\n",
    "\n",
    "    model_fit = model.fit(train_vectors[0].numpy(),train_vectors[0].numpy(), batch_size=len(train_vectors[0]), epochs=10000, verbose=0, callbacks=my_callbacks, \n",
    "                            validation_split=0.0, validation_data=(val_vectors[0].numpy(), val_vectors[0].numpy()), shuffle=True, validation_batch_size=None)\n",
    "    \n",
    "    model_history[f'1_hidden_layer_{num_neurons}_neurons'] = model_fit.history['mse']\n",
    "    \n",
    "    hist_metric = 'mse'\n",
    "    print(f'epochs: {len(model_fit.history[hist_metric])}, mse: {model_fit.history[hist_metric][-1]}\\n')\n",
    "    model.save(f'models/Q2/1_hidden_layer_{num_neurons}_neurons.tf')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying reconstructed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group_24/train/0/img_1.jpg\n",
    "# Group_24/test/0/img_23.jpg\n",
    "# Group_24/val/0/img_111.jpg\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Hidden layer autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 3 Hidden Layer autoencoder with different number of neurons in bottleneck layer\n",
      "1 Hidden Layer : 32 neurons\n",
      "epochs: 283, mse: 0.05878017470240593\n",
      "\n",
      "1 Hidden Layer : 64 neurons\n",
      "epochs: 280, mse: 0.05350026115775108\n",
      "\n",
      "1 Hidden Layer : 128 neurons\n",
      "epochs: 274, mse: 0.047249697148799896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initializer = initializers.RandomNormal(mean=0.0, stddev=0.05, seed=42)\n",
    "\n",
    "k=5 # no. of classes\n",
    "model_history = dict()\n",
    "\n",
    "# train different achitectures and optimizers\n",
    "print('Training 3 Hidden Layer autoencoder with different number of neurons in bottleneck layer')\n",
    "for num_neurons in [32, 64, 128, 256]:\n",
    "    print(f'1 Hidden Layer : {num_neurons} neurons')\n",
    "    # define model\n",
    "    model = Sequential([\n",
    "        layers.Dense(784, activation=\"relu\", input_shape=(784,)),\n",
    "        layers.Dense(400, activation=\"sigmoid\", name=\"hidden1\", \n",
    "                        kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "        layers.Dense(num_neurons, activation=\"sigmoid\", name=\"bottleneck\", \n",
    "                        kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "        layers.Dense(400, activation=\"sigmoid\", name=\"hidden3\", \n",
    "                        kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "        layers.Dense(784, activation=\"relu\", name=\"output\", \n",
    "                        kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "    ])\n",
    "    \n",
    "    # compile model\n",
    "    loss = tf.keras.losses.MeanSquaredError()\n",
    "    adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "    model.compile(optimizer=adam_optimizer, loss=loss, metrics=['mse'])\n",
    "    \n",
    "    # callbacks\n",
    "    my_callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5),\n",
    "        TensorBoard(log_dir=f'./logdir/Q2/3_hidden_layer_{num_neurons}_neurons/')\n",
    "    ]\n",
    "\n",
    "    model_fit = model.fit(train_vectors[0].numpy(),train_vectors[0].numpy(), batch_size=len(train_vectors[0]), epochs=10000, verbose=0, callbacks=my_callbacks, \n",
    "                            validation_split=0.0, validation_data=(val_vectors[0].numpy(), val_vectors[0].numpy()), shuffle=True, validation_batch_size=None)\n",
    "    \n",
    "    model_history[f'3_hidden_layer_{num_neurons}_neurons'] = model_fit.history['mse']\n",
    "    \n",
    "    hist_metric = 'mse'\n",
    "    print(f'epochs: {len(model_fit.history[hist_metric])}, mse: {model_fit.history[hist_metric][-1]}\\n')\n",
    "    model.save(f'models/Q2/3_hidden_layer_{num_neurons}_neurons.tf')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
