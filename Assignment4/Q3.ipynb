{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam, SGD, Adagrad, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data, normalizing and flattening it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading and Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = image_dataset_from_directory(\n",
    "    'Group_24/train/',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=1,\n",
    "    image_size=(28, 28),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    color_mode='grayscale',\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "val = image_dataset_from_directory(\n",
    "    'Group_24/val/',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=1,\n",
    "    image_size=(28, 28),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    color_mode='grayscale',\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "test = image_dataset_from_directory(\n",
    "    'Group_24/test/',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=1,\n",
    "    image_size=(28, 28),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    color_mode='grayscale',\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "def normalize(image,label):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image, label\n",
    "\n",
    "train = train.map(normalize)\n",
    "val = val.map(normalize)\n",
    "test = test.map(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Flattening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing training tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataset and reshape each image tensor\n",
    "image_tensors = []\n",
    "label_tensors = []\n",
    "for image, labels in train:\n",
    "    num_images = image.shape[0]\n",
    "    image_vectors = tf.reshape(image, [num_images, -1])\n",
    "    image_tensors.append(image_vectors)\n",
    "    label_tensors.append(labels)\n",
    "\n",
    "# Concatenate the image tensors into a single tensor\n",
    "train_vectors = [tf.concat(image_tensors, axis=0), tf.concat(label_tensors, axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing validation tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataset and reshape each image tensor\n",
    "image_tensors = []\n",
    "label_tensors = []\n",
    "for image, labels in val:\n",
    "    num_images = image.shape[0]\n",
    "    image_vectors = tf.reshape(image, [num_images, -1])\n",
    "    image_tensors.append(image_vectors)\n",
    "    label_tensors.append(labels)\n",
    "\n",
    "# Concatenate the image tensors into a single tensor\n",
    "val_vectors = [tf.concat(image_tensors, axis=0), tf.concat(label_tensors, axis=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing testing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataset and reshape each image tensor\n",
    "image_tensors = []\n",
    "label_tensors = []\n",
    "for image, labels in test:\n",
    "    num_images = image.shape[0]\n",
    "    image_vectors = tf.reshape(image, [num_images, -1])\n",
    "    image_tensors.append(image_vectors)\n",
    "    label_tensors.append(labels)\n",
    "\n",
    "# Concatenate the image tensors into a single tensor\n",
    "test_vectors = [tf.concat(image_tensors, axis=0), tf.concat(label_tensors, axis=0)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding compressed representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reduced_representation(dim, vec):\n",
    "    models = os.listdir('./models/Q2')\n",
    "    model_path = str\n",
    "    for model in models:\n",
    "        if( (\"1_hidden\" in model) and ((str(dim)+\"_n\") in model)) : model_path = model\n",
    "    loaded_model = tf.keras.models.load_model(os.path.join('./models/Q2', model_path))\n",
    "    hidden_layer_model = tf.keras.models.Model(inputs=loaded_model.input, outputs=loaded_model.layers[1].output)\n",
    "    hidden_output = hidden_layer_model.predict(vec[0].numpy().reshape(len(vec[0]),784))\n",
    "    return hidden_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arch = [\n",
    "    [96, 64, 32],\n",
    "    [64, 96, 128],\n",
    "    [128, 96, 64],\n",
    "    [256, 128, 96]\n",
    "]\n",
    "initializer = initializers.RandomNormal(mean=0.0, stddev=0.05, seed=42)\n",
    "\n",
    "k=5 # no. of classes\n",
    "model_history = dict()\n",
    "\n",
    "# train different achitectures and optimizers\n",
    "print('Training models with different architectures')\n",
    "for reduced_dimension in [32,64,128,256]:\n",
    "    reduced_rep_train = get_reduced_representation(reduced_dimension, train_vectors)\n",
    "    reduced_rep_val = get_reduced_representation(reduced_dimension, val_vectors)\n",
    "    for layer_dims in model_arch:\n",
    "        print(f'{reduced_dimension}-{layer_dims[0]}-{layer_dims[1]}-{layer_dims[2]}...')\n",
    "        # define model\n",
    "        model = Sequential([\n",
    "            layers.Dense(reduced_dimension, activation=\"relu\", input_shape=(reduced_dimension,)),\n",
    "            # keras.Input(input_shape=(reduced_dimension,)),\n",
    "            layers.Dense(layer_dims[0], activation=\"sigmoid\", name=\"layer1\", \n",
    "                         kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "            layers.Dense(layer_dims[1], activation=\"sigmoid\", name=\"layer2\", \n",
    "                         kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "            layers.Dense(layer_dims[2], activation=\"sigmoid\", name=\"layer3\", \n",
    "                         kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "            # layers.Dense(layer_dims[3], activation=\"sigmoid\", name=\"layer4\", \n",
    "            #              kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "            layers.Dense(k, activation=\"softmax\", name=\"output\", \n",
    "                         kernel_initializer=initializer, bias_initializer=initializers.Zeros()),\n",
    "        ])\n",
    "        \n",
    "        # compile model\n",
    "        adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "        model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # callbacks\n",
    "        my_callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', min_delta=1e-7, patience=10),\n",
    "            TensorBoard(log_dir=f'./logdir/Q3/{reduced_dimension}-{layer_dims[0]}-{layer_dims[1]}-{layer_dims[2]}/')\n",
    "        ]\n",
    "        model_fit = model.fit(reduced_rep_train, train_vectors[1].numpy(), batch_size=len(train_vectors[0]), epochs=10000, verbose=0, callbacks=my_callbacks, \n",
    "                              validation_split=0.0, validation_data=(reduced_rep_val, val_vectors[1].numpy()), shuffle=True, validation_batch_size=None)\n",
    "        \n",
    "        model_history[f'{reduced_dimension}-{layer_dims[0]}-{layer_dims[1]}-{layer_dims[2]}'] = model_fit.history['accuracy']\n",
    "        \n",
    "        hist_metric = 'accuracy'\n",
    "        print(f'epochs: {len(model_fit.history[hist_metric])}, acc: {model_fit.history[hist_metric][-1]}\\n')\n",
    "        model.save(f'models/Q3/{reduced_dimension}-{layer_dims[0]}-{layer_dims[1]}-{layer_dims[2]}.tf')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
