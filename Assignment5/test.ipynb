{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam, SGD, Adagrad, RMSprop\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D , MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.models import Model\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from numpy import expand_dims\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = image_dataset_from_directory(\n",
    "    'Group_24/train/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=1,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "val = image_dataset_from_directory(\n",
    "    'Group_24/val/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=1,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.0\n",
    ")\n",
    "\n",
    "test = image_dataset_from_directory(\n",
    "    'Group_24/test/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=1,\n",
    "    image_size=(224, 224),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.0\n",
    ")\n",
    "class_names = train.class_names\n",
    "def normalize(image,label):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image, label\n",
    "\n",
    "train_data = train.map(normalize)\n",
    "val_data = val.map(normalize)\n",
    "test_data = test.map(normalize)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = layers.Input(shape=(224, 224, 3))\n",
    "conv1 = layers.Conv2D(8, (11, 11), strides=4, padding='same', activation='relu')(input_layer)\n",
    "max_pool1 = layers.MaxPooling2D((3, 3), strides=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(16, (5, 5), strides=1, padding='same', activation='relu')(max_pool1)\n",
    "max_pool2 = layers.MaxPooling2D((3, 3), strides=2)(conv2)\n",
    "flatten = layers.Flatten()(max_pool2)\n",
    "dense1 = layers.Dense(128, activation='relu')(flatten)\n",
    "output_layer = layers.Dense(5, activation ='softmax')(dense1)\n",
    "\n",
    "adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "# model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=0), optimizer=adam_optimizer, metrics=['accuracy'])\n",
    "\n",
    "# callbacks\n",
    "my_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=10),\n",
    "    TensorBoard(log_dir=f'./logdir/Q1/Arch1/')\n",
    "]\n",
    "# out = model.fit(train_data, validation_data=val_data, epochs=100, callbacks=my_callbacks)\n",
    "model_fit = model.fit(train_data,validation_data=val_data, batch_size=len(train_data), epochs=100, verbose=0, callbacks=my_callbacks, validation_split=0.0, shuffle=True, validation_batch_size=None)\n",
    "\n",
    "hist_metric = 'accuracy'\n",
    "print(f'epochs: {len(model_fit.history[hist_metric])}, acc: {model_fit.history[hist_metric][-1]}\\n')\n",
    "model.save(f'models/Q1/Arch1.tf')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy history\n",
    "acc = model_fit.history['accuracy']\n",
    "val_acc = model_fit.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy (Arch 1)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy and confusion matrix\n",
    "train_loss, train_acc = model.evaluate(train_data, verbose=0)\n",
    "train_pred = model.predict(train_data)\n",
    "train_labels = tf.concat([q for p, q in train_data], axis=0)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(tf.math.confusion_matrix(tf.argmax(train_labels,axis=1),tf.argmax(train_pred,axis=1),num_classes=5))\n",
    "# val accuracy and confusion matrix\n",
    "val_loss, val_acc = model.evaluate(val_data, verbose=0)\n",
    "val_pred = model.predict(val_data)\n",
    "val_labels = tf.concat([q for p, q in val_data], axis=0)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(tf.math.confusion_matrix(tf.argmax(val_labels,axis=1),tf.argmax(val_pred,axis=1),num_classes=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(train_data, verbose=0)\n",
    "train_pred = model.predict(train_data)\n",
    "train_labels = tf.concat([q for p, q in train_data], axis=0)\n",
    "\n",
    "val_loss, val_acc = model.evaluate(val_data, verbose=2)\n",
    "val_pred = model.predict(val_data)\n",
    "val_labels = tf.concat([q for p, q in val_data], axis=0)\n",
    "\n",
    "print('Confusion matrix (train):')\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(tf.argmax(train_labels,axis=1),tf.argmax(train_pred,axis=1)), display_labels=class_names)\n",
    "cm_display.plot(ax = ax, cmap='Greys', colorbar=True)\n",
    "plt.show()\n",
    "\n",
    "print('Confusion matrix (val):')\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(tf.argmax(val_labels,axis=1),tf.argmax(val_pred,axis=1)), display_labels=class_names)\n",
    "cm_display.plot(ax = ax, cmap='Greys', colorbar=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = layers.Input(shape=(224, 224, 3))\n",
    "conv1 = layers.Conv2D(8, (11, 11), strides=4, padding='same', activation='relu')(input_layer)\n",
    "max_pool1 = layers.MaxPooling2D((3, 3), strides=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(16, (5, 5), strides=1, padding='same', activation='relu')(max_pool1)\n",
    "max_pool2 = layers.MaxPooling2D((3, 3), strides=2)(conv2)\n",
    "conv3 = layers.Conv2D(32, (3, 3), strides=1, padding='same', activation='relu')(max_pool2)\n",
    "max_pool3 = layers.MaxPooling2D((3,3), strides=2)(conv3)\n",
    "flatten = layers.Flatten()(max_pool3)\n",
    "dense1 = layers.Dense(128, activation='relu')(flatten)\n",
    "output_layer = layers.Dense(5, activation ='softmax')(dense1)\n",
    "\n",
    "adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "# model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=0), optimizer=adam_optimizer, metrics=['accuracy'])\n",
    "\n",
    "# callbacks\n",
    "my_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=10),\n",
    "    TensorBoard(log_dir=f'./logdir/Q1/Arch2/')\n",
    "]\n",
    "# out = model.fit(train_data, validation_data=val_data, epochs=100, callbacks=my_callbacks)\n",
    "model_fit = model.fit(train_data,validation_data=val_data, batch_size=len(train_data), epochs=100, verbose=0, callbacks=my_callbacks, validation_split=0.0, shuffle=True, validation_batch_size=None)\n",
    "\n",
    "hist_metric = 'accuracy'\n",
    "print(f'epochs: {len(model_fit.history[hist_metric])}, acc: {model_fit.history[hist_metric][-1]}\\n')\n",
    "model.save(f'models/Q1/Arch2.tf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy history\n",
    "acc = model_fit.history['accuracy']\n",
    "val_acc = model_fit.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy (Arch 1)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy and confusion matrix\n",
    "train_loss, train_acc = model.evaluate(train_data, verbose=0)\n",
    "train_pred = model.predict(train_data)\n",
    "train_labels = tf.concat([q for p, q in train_data], axis=0)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(tf.math.confusion_matrix(tf.argmax(train_labels,axis=1),tf.argmax(train_pred,axis=1),num_classes=5))\n",
    "# val accuracy and confusion matrix\n",
    "val_loss, val_acc = model.evaluate(val_data, verbose=0)\n",
    "val_pred = model.predict(val_data)\n",
    "val_labels = tf.concat([q for p, q in val_data], axis=0)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(tf.math.confusion_matrix(tf.argmax(val_labels,axis=1),tf.argmax(val_pred,axis=1),num_classes=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(train_data, verbose=0)\n",
    "train_pred = model.predict(train_data)\n",
    "train_labels = tf.concat([q for p, q in train_data], axis=0)\n",
    "\n",
    "val_loss, val_acc = model.evaluate(val_data, verbose=2)\n",
    "val_pred = model.predict(val_data)\n",
    "val_labels = tf.concat([q for p, q in val_data], axis=0)\n",
    "\n",
    "print('Confusion matrix (train):')\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(tf.argmax(train_labels,axis=1),tf.argmax(train_pred,axis=1)), display_labels=class_names)\n",
    "cm_display.plot(ax = ax, cmap='Greys', colorbar=True)\n",
    "plt.show()\n",
    "\n",
    "print('Confusion matrix (val):')\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(tf.argmax(val_labels,axis=1),tf.argmax(val_pred,axis=1)), display_labels=class_names)\n",
    "cm_display.plot(ax = ax, cmap='Greys', colorbar=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = layers.Input(shape=(224, 224, 3))\n",
    "conv1 = layers.Conv2D(8, (11, 11), strides=4, padding='same', activation='relu')(input_layer)\n",
    "max_pool1 = layers.MaxPooling2D((3, 3), strides=(2, 2))(conv1)\n",
    "conv2 = layers.Conv2D(16, (5, 5), strides=1, padding='same', activation='relu')(max_pool1)\n",
    "max_pool2 = layers.MaxPooling2D((3, 3), strides=2)(conv2)\n",
    "conv3 = layers.Conv2D(32, (3, 3), strides=1, padding='same', activation='relu')(max_pool2)\n",
    "conv4 = layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu')(conv3)\n",
    "max_pool3 = layers.MaxPooling2D((3, 3), strides=2)(conv4)\n",
    "flatten = layers.Flatten()(max_pool3)\n",
    "dense1 = layers.Dense(128, activation='relu')(flatten)\n",
    "output_layer = layers.Dense(5, activation ='softmax')(dense1)\n",
    "\n",
    "adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "# model.compile(optimizer=adam_optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=0), optimizer=adam_optimizer, metrics=['accuracy'])\n",
    "\n",
    "# callbacks\n",
    "my_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=1e-7, patience=10),\n",
    "    TensorBoard(log_dir=f'./logdir/Q1/Arch3/')\n",
    "]\n",
    "# out = model.fit(train_data, validation_data=val_data, epochs=100, callbacks=my_callbacks)\n",
    "model_fit = model.fit(train_data,validation_data=val_data, batch_size=len(train_data), epochs=100, verbose=0, callbacks=my_callbacks, validation_split=0.0, shuffle=True, validation_batch_size=None)\n",
    "\n",
    "hist_metric = 'accuracy'\n",
    "print(f'epochs: {len(model_fit.history[hist_metric])}, acc: {model_fit.history[hist_metric][-1]}\\n')\n",
    "model.save(f'models/Q1/Arch3.tf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy history\n",
    "acc = model_fit.history['accuracy']\n",
    "val_acc = model_fit.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy (Arch 1)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy and confusion matrix\n",
    "train_loss, train_acc = model.evaluate(train_data, verbose=0)\n",
    "train_pred = model.predict(train_data)\n",
    "train_labels = tf.concat([q for p, q in train_data], axis=0)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(tf.math.confusion_matrix(tf.argmax(train_labels,axis=1),tf.argmax(train_pred,axis=1),num_classes=5))\n",
    "# val accuracy and confusion matrix\n",
    "val_loss, val_acc = model.evaluate(val_data, verbose=0)\n",
    "val_pred = model.predict(val_data)\n",
    "val_labels = tf.concat([q for p, q in val_data], axis=0)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(tf.math.confusion_matrix(tf.argmax(val_labels,axis=1),tf.argmax(val_pred,axis=1),num_classes=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(train_data, verbose=0)\n",
    "train_pred = model.predict(train_data)\n",
    "train_labels = tf.concat([q for p, q in train_data], axis=0)\n",
    "\n",
    "val_loss, val_acc = model.evaluate(val_data, verbose=2)\n",
    "val_pred = model.predict(val_data)\n",
    "val_labels = tf.concat([q for p, q in val_data], axis=0)\n",
    "\n",
    "print('Confusion matrix (train):')\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(tf.argmax(train_labels,axis=1),tf.argmax(train_pred,axis=1)), display_labels=class_names)\n",
    "cm_display.plot(ax = ax, cmap='Greys', colorbar=True)\n",
    "plt.show()\n",
    "\n",
    "print('Confusion matrix (val):')\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix(tf.argmax(val_labels,axis=1),tf.argmax(val_pred,axis=1)), display_labels=class_names)\n",
    "cm_display.plot(ax = ax, cmap='Greys', colorbar=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature maps for best architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = [image.numpy() for image, label in train_data.take(1)][0]\n",
    "plt.imshow(image[0])\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature maps\n",
    "for i in [1,3,5]:\n",
    "    part_model = Model(inputs=model.inputs, outputs=model.layers[i].output)\n",
    "    # get feature map for first hidden layer\n",
    "    print(image.shape)\n",
    "    feature_maps = part_model.predict(image)\n",
    "\n",
    "    fig, ax = plt.subplots(2,4, figsize=(8,4))\n",
    "    for j in range(8):\n",
    "        ax[int(j/4)][int(j%4)].imshow(feature_maps[0, :, :, j],'viridis')\n",
    "        ax[int(j/4)][int(j%4)].axis(\"off\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximally activating patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your trained model\n",
    "model = tf.keras.models.load_model('your_model.h5')\n",
    "\n",
    "# Select a sample image from the training set of each class\n",
    "class_1_image = ...\n",
    "class_2_image = ...\n",
    "class_3_image = ...\n",
    "class_4_image = ...\n",
    "class_5_image = ...\n",
    "\n",
    "# Get the output of the last convolutional layer\n",
    "last_conv_layer = model.get_layer('name_of_last_conv_layer')\n",
    "last_conv_layer_model = tf.keras.Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "# Get the gradients of the output of the last convolutional layer with respect to the input image\n",
    "grad_model = tf.keras.models.Model([model.inputs], tf.gradients(last_conv_layer_model.output, model.inputs))\n",
    "\n",
    "# Define a function to get the most activated patch in the input image\n",
    "def get_most_activated_patch(img, model):\n",
    "    # Reshape the input image to match the model's input shape\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # Get the output of the last convolutional layer and the gradients of the output with respect to the input\n",
    "    last_conv_output = last_conv_layer_model.predict(img)\n",
    "    grads = grad_model(img)\n",
    "\n",
    "    # Get the most activated neuron in the last convolutional layer\n",
    "    max_activation_idx = np.argmax(last_conv_output[0,:,:,0])\n",
    "    max_activation = last_conv_output[0,:,:,max_activation_idx]\n",
    "\n",
    "    # Get the gradients corresponding to the most activated neuron\n",
    "    pooled_grads = np.mean(grads[0], axis=(0, 1, 2))\n",
    "    activation_grads = last_conv_output[0,:,:,max_activation_idx] * pooled_grads\n",
    "\n",
    "    # Get the most activated patch in the input image\n",
    "    heatmap = np.mean(activation_grads, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    heatmap = heatmap.astype('float32')\n",
    "    img = img[0,:,:,:]\n",
    "    heatmap = tf.image.resize(heatmap, (img.shape[0], img.shape[1]))\n",
    "    heatmap = heatmap.numpy()\n",
    "    mask = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(mask, cv2.COLORMAP_JET)\n",
    "    superimposed_img = cv2.addWeighted(img, 0.5, heatmap, 0.5, 0)\n",
    "    return superimposed_img\n",
    "\n",
    "# Get the most activated patch in each image and display them\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.imshow(get_most_activated_patch(class_1_image, model))\n",
    "plt.subplot(1, 5, 2)\n",
    "plt.imshow(get_most_activated_patch(class_2_image, model))\n",
    "plt.subplot(1, 5, 3)\n",
    "plt.imshow(get_most_activated_patch(class_3_image, model))\n",
    "plt.subplot(1, 5, 4)\n",
    "plt.imshow(get_most_activated_patch(class_4_image, model))\n",
    "plt.subplot(1, 5, 5)\n",
    "plt.imshow(get_most_activated_patch(class_5_image, model))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
