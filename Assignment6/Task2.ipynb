{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import warnings\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD, Adagrad, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, Callback\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = [], []\n",
    "z_train, z_test = [], []\n",
    "# chars =  [\"bhA\", \"ba\", \"tA\", \"kaa\", \"tI\"]\n",
    "chars = [\"hai\", \"ka\", \"rI\", \"sa\", \"pa\"]\n",
    "\n",
    "def read_ip(path):\n",
    "    seq = []\n",
    "    with open(path, 'r') as file:\n",
    "        # Iterate over the lines in the file\n",
    "        for line in file:\n",
    "            data = [float(freq) for freq in line.split()]\n",
    "            seq.append(data)\n",
    "    return seq\n",
    "\n",
    "for ch in chars:\n",
    "    for f in os.listdir(\"Group24/CV_Data/\" + str(ch)+\"/Train\"):\n",
    "        train.append(read_ip(\"Group24/CV_Data/\" + str(ch)+\"/Train/\" + str(f)))\n",
    "        z_train.append(str(ch))\n",
    "    for f in os.listdir(\"Group24/CV_Data/\" + str(ch)+\"/Test\"):\n",
    "        test.append(read_ip(\"Group24/CV_Data/\" + str(ch) + \"/Test/\" + str(f)))\n",
    "        z_test.append(str(ch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, z_train, z_val = train_test_split(train, z_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_map = {\"bhA\":0, \"ba\":1, \"tA\":2, \"kaa\":3, \"tI\":4}\n",
    "label_map = {\"hai\":0, \"ka\":1, \"rI\":2, \"sa\":3, \"pa\":4}\n",
    "z_train_onehot = tf.keras.utils.to_categorical([label_map[x] for x in z_train], 5)\n",
    "z_val_onehot = tf.keras.utils.to_categorical([label_map[x] for x in z_val], 5)\n",
    "z_test_onehot = tf.keras.utils.to_categorical([label_map[x] for x in z_test], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 17:11:49.817051: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-05-09 17:11:49.817078: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-05-09 17:11:49.817095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (piyush-HP-Spectre-x360-Convertible-13-aw2xxx): /proc/driver/nvidia/version does not exist\n",
      "2023-05-09 17:11:49.817355: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_tensor = tf.ragged.constant(train)\n",
    "test_tensor = tf.ragged.constant(test)\n",
    "val_tensor = tf.ragged.constant(val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(256, batch_input_shape=(None, None, 39), return_sequences=True))\n",
    "model.add(SimpleRNN(128, activation=\"relu\", return_sequences=True))\n",
    "model.add(SimpleRNN(64, activation=\"relu\", return_sequences=True))\n",
    "model.add(SimpleRNN(32, activation=\"relu\", return_sequences=False))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam_optimizer, metrics=['accuracy']) \n",
    "# Train the model\n",
    "my_callbacks = [ EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=20),    TensorBoard(log_dir=f'./logdir/Q1/test')]\n",
    "model_fit = model.fit(train_tensor, z_train_onehot, validation_data=(val_tensor, z_val_onehot), batch_size=len(train), epochs=10000, verbose=1, validation_split=0.0,callbacks=my_callbacks, shuffle=False, validation_batch_size=None)\n",
    "\n",
    "hist_metric = 'accuracy'\n",
    "print(f'epochs: {len(model_fit.history[hist_metric])}, acc: {model_fit.history[hist_metric][-1]}\\n')\n",
    "model.save(f'models/Q1/test.tf')\n",
    "\n",
    "loss, accuracy = model.evaluate(test_tensor,z_test_onehot)\n",
    "\n",
    "print(\"Test loss = \", loss)\n",
    "print(\"Test accuracy = \", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.7985 - accuracy: 0.2504 - val_loss: 1.7435 - val_accuracy: 0.2415\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.7281 - accuracy: 0.2795 - val_loss: 1.6808 - val_accuracy: 0.2614\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.6622 - accuracy: 0.3009 - val_loss: 1.6225 - val_accuracy: 0.2955\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.6017 - accuracy: 0.3257 - val_loss: 1.5679 - val_accuracy: 0.3381\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.5462 - accuracy: 0.3542 - val_loss: 1.5162 - val_accuracy: 0.3892\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 1.4948 - accuracy: 0.3876 - val_loss: 1.4676 - val_accuracy: 0.4062\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.4471 - accuracy: 0.4203 - val_loss: 1.4227 - val_accuracy: 0.4403\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 1.4025 - accuracy: 0.4445 - val_loss: 1.3811 - val_accuracy: 0.4545\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 1.3605 - accuracy: 0.4694 - val_loss: 1.3421 - val_accuracy: 0.4688\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 1.3210 - accuracy: 0.4922 - val_loss: 1.3056 - val_accuracy: 0.4886\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.2840 - accuracy: 0.5121 - val_loss: 1.2709 - val_accuracy: 0.4972\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 1.2491 - accuracy: 0.5427 - val_loss: 1.2379 - val_accuracy: 0.5483\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 1.2161 - accuracy: 0.5612 - val_loss: 1.2064 - val_accuracy: 0.5625\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 1.1845 - accuracy: 0.5733 - val_loss: 1.1762 - val_accuracy: 0.5710\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 1.1544 - accuracy: 0.5868 - val_loss: 1.1474 - val_accuracy: 0.5909\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 1.1253 - accuracy: 0.5960 - val_loss: 1.1197 - val_accuracy: 0.5994\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 1.0973 - accuracy: 0.6131 - val_loss: 1.0932 - val_accuracy: 0.6108\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 1.0704 - accuracy: 0.6273 - val_loss: 1.0681 - val_accuracy: 0.6278\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 1.0444 - accuracy: 0.6373 - val_loss: 1.0440 - val_accuracy: 0.6364\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 1.0194 - accuracy: 0.6494 - val_loss: 1.0209 - val_accuracy: 0.6477\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.9953 - accuracy: 0.6600 - val_loss: 0.9991 - val_accuracy: 0.6619\n",
      "Epoch 22/10000\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.9722 - accuracy: 0.6679 - val_loss: 0.9784 - val_accuracy: 0.6619\n",
      "Epoch 23/10000\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.9498 - accuracy: 0.6757 - val_loss: 0.9587 - val_accuracy: 0.6562\n",
      "Epoch 24/10000\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.9281 - accuracy: 0.6821 - val_loss: 0.9394 - val_accuracy: 0.6705\n",
      "Epoch 25/10000\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.9071 - accuracy: 0.6899 - val_loss: 0.9203 - val_accuracy: 0.6761\n",
      "Epoch 26/10000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8866 - accuracy: 0.7013 - val_loss: 0.9014 - val_accuracy: 0.6847\n",
      "Epoch 27/10000\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.8669 - accuracy: 0.7077 - val_loss: 0.8832 - val_accuracy: 0.6932\n",
      "Epoch 28/10000\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.8478 - accuracy: 0.7148 - val_loss: 0.8656 - val_accuracy: 0.6932\n",
      "Epoch 29/10000\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.8294 - accuracy: 0.7191 - val_loss: 0.8486 - val_accuracy: 0.6932\n",
      "Epoch 30/10000\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.8115 - accuracy: 0.7255 - val_loss: 0.8320 - val_accuracy: 0.6989\n",
      "Epoch 31/10000\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.7942 - accuracy: 0.7383 - val_loss: 0.8159 - val_accuracy: 0.7017\n",
      "Epoch 32/10000\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.7771 - accuracy: 0.7425 - val_loss: 0.8003 - val_accuracy: 0.7102\n",
      "Epoch 33/10000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.7605 - accuracy: 0.7504 - val_loss: 0.7854 - val_accuracy: 0.7188\n",
      "Epoch 34/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.7441 - accuracy: 0.7575 - val_loss: 0.7713 - val_accuracy: 0.7358\n",
      "Epoch 35/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.7280 - accuracy: 0.7603 - val_loss: 0.7580 - val_accuracy: 0.7443\n",
      "Epoch 36/10000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.7123 - accuracy: 0.7639 - val_loss: 0.7452 - val_accuracy: 0.7472\n",
      "Epoch 37/10000\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.6968 - accuracy: 0.7710 - val_loss: 0.7329 - val_accuracy: 0.7557\n",
      "Epoch 38/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.6817 - accuracy: 0.7738 - val_loss: 0.7208 - val_accuracy: 0.7585\n",
      "Epoch 39/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.6666 - accuracy: 0.7767 - val_loss: 0.7089 - val_accuracy: 0.7642\n",
      "Epoch 40/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.6518 - accuracy: 0.7845 - val_loss: 0.6974 - val_accuracy: 0.7727\n",
      "Epoch 41/10000\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.6375 - accuracy: 0.7873 - val_loss: 0.6862 - val_accuracy: 0.7727\n",
      "Epoch 42/10000\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 0.6236 - accuracy: 0.7945 - val_loss: 0.6753 - val_accuracy: 0.7699\n",
      "Epoch 43/10000\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.6100 - accuracy: 0.7987 - val_loss: 0.6646 - val_accuracy: 0.7727\n",
      "Epoch 44/10000\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.5967 - accuracy: 0.8044 - val_loss: 0.6543 - val_accuracy: 0.7727\n",
      "Epoch 45/10000\n",
      "1/1 [==============================] - 0s 383ms/step - loss: 0.5836 - accuracy: 0.8058 - val_loss: 0.6444 - val_accuracy: 0.7756\n",
      "Epoch 46/10000\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.5707 - accuracy: 0.8122 - val_loss: 0.6346 - val_accuracy: 0.7784\n",
      "Epoch 47/10000\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 0.5579 - accuracy: 0.8165 - val_loss: 0.6250 - val_accuracy: 0.7756\n",
      "Epoch 48/10000\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 0.5454 - accuracy: 0.8201 - val_loss: 0.6156 - val_accuracy: 0.7756\n",
      "Epoch 49/10000\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.5331 - accuracy: 0.8286 - val_loss: 0.6065 - val_accuracy: 0.7812\n",
      "Epoch 50/10000\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.5211 - accuracy: 0.8350 - val_loss: 0.5978 - val_accuracy: 0.7812\n",
      "Epoch 51/10000\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.5093 - accuracy: 0.8414 - val_loss: 0.5893 - val_accuracy: 0.7869\n",
      "Epoch 52/10000\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.4978 - accuracy: 0.8464 - val_loss: 0.5811 - val_accuracy: 0.7869\n",
      "Epoch 53/10000\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.4865 - accuracy: 0.8521 - val_loss: 0.5731 - val_accuracy: 0.7926\n",
      "Epoch 54/10000\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.4753 - accuracy: 0.8578 - val_loss: 0.5653 - val_accuracy: 0.7983\n",
      "Epoch 55/10000\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.4643 - accuracy: 0.8627 - val_loss: 0.5576 - val_accuracy: 0.8011\n",
      "Epoch 56/10000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.4534 - accuracy: 0.8691 - val_loss: 0.5502 - val_accuracy: 0.8011\n",
      "Epoch 57/10000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.4429 - accuracy: 0.8727 - val_loss: 0.5431 - val_accuracy: 0.8068\n",
      "Epoch 58/10000\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.4326 - accuracy: 0.8748 - val_loss: 0.5363 - val_accuracy: 0.8040\n",
      "Epoch 59/10000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.4226 - accuracy: 0.8770 - val_loss: 0.5299 - val_accuracy: 0.8153\n",
      "Epoch 60/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.4128 - accuracy: 0.8798 - val_loss: 0.5239 - val_accuracy: 0.8153\n",
      "Epoch 61/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.4031 - accuracy: 0.8834 - val_loss: 0.5183 - val_accuracy: 0.8153\n",
      "Epoch 62/10000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.3937 - accuracy: 0.8876 - val_loss: 0.5128 - val_accuracy: 0.8210\n",
      "Epoch 63/10000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.3846 - accuracy: 0.8890 - val_loss: 0.5074 - val_accuracy: 0.8239\n",
      "Epoch 64/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.3757 - accuracy: 0.8912 - val_loss: 0.5020 - val_accuracy: 0.8239\n",
      "Epoch 65/10000\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.3669 - accuracy: 0.8969 - val_loss: 0.4967 - val_accuracy: 0.8295\n",
      "Epoch 66/10000\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.3581 - accuracy: 0.8997 - val_loss: 0.4912 - val_accuracy: 0.8295\n",
      "Epoch 67/10000\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.3493 - accuracy: 0.9033 - val_loss: 0.4857 - val_accuracy: 0.8324\n",
      "Epoch 68/10000\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.3409 - accuracy: 0.9047 - val_loss: 0.4801 - val_accuracy: 0.8324\n",
      "Epoch 69/10000\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.3326 - accuracy: 0.9054 - val_loss: 0.4744 - val_accuracy: 0.8352\n",
      "Epoch 70/10000\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.3245 - accuracy: 0.9083 - val_loss: 0.4688 - val_accuracy: 0.8381\n",
      "Epoch 71/10000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.3166 - accuracy: 0.9097 - val_loss: 0.4631 - val_accuracy: 0.8381\n",
      "Epoch 72/10000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.3087 - accuracy: 0.9125 - val_loss: 0.4576 - val_accuracy: 0.8409\n",
      "Epoch 73/10000\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.3010 - accuracy: 0.9147 - val_loss: 0.4522 - val_accuracy: 0.8409\n",
      "Epoch 74/10000\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 0.2934 - accuracy: 0.9168 - val_loss: 0.4470 - val_accuracy: 0.8438\n",
      "Epoch 75/10000\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.2859 - accuracy: 0.9203 - val_loss: 0.4421 - val_accuracy: 0.8466\n",
      "Epoch 76/10000\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.2786 - accuracy: 0.9239 - val_loss: 0.4376 - val_accuracy: 0.8551\n",
      "Epoch 77/10000\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.2714 - accuracy: 0.9253 - val_loss: 0.4335 - val_accuracy: 0.8551\n",
      "Epoch 78/10000\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.2644 - accuracy: 0.9282 - val_loss: 0.4296 - val_accuracy: 0.8580\n",
      "Epoch 79/10000\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.2577 - accuracy: 0.9317 - val_loss: 0.4257 - val_accuracy: 0.8580\n",
      "Epoch 80/10000\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.2511 - accuracy: 0.9360 - val_loss: 0.4216 - val_accuracy: 0.8580\n",
      "Epoch 81/10000\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.2447 - accuracy: 0.9403 - val_loss: 0.4173 - val_accuracy: 0.8608\n",
      "Epoch 82/10000\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.2384 - accuracy: 0.9424 - val_loss: 0.4133 - val_accuracy: 0.8693\n",
      "Epoch 83/10000\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.2323 - accuracy: 0.9452 - val_loss: 0.4097 - val_accuracy: 0.8636\n",
      "Epoch 84/10000\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 0.2264 - accuracy: 0.9481 - val_loss: 0.4064 - val_accuracy: 0.8580\n",
      "Epoch 85/10000\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.2207 - accuracy: 0.9488 - val_loss: 0.4031 - val_accuracy: 0.8580\n",
      "Epoch 86/10000\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.2152 - accuracy: 0.9502 - val_loss: 0.3993 - val_accuracy: 0.8608\n",
      "Epoch 87/10000\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.2098 - accuracy: 0.9516 - val_loss: 0.3954 - val_accuracy: 0.8636\n",
      "Epoch 88/10000\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 0.2045 - accuracy: 0.9523 - val_loss: 0.3919 - val_accuracy: 0.8722\n",
      "Epoch 89/10000\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.1994 - accuracy: 0.9545 - val_loss: 0.3890 - val_accuracy: 0.8750\n",
      "Epoch 90/10000\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.1944 - accuracy: 0.9538 - val_loss: 0.3863 - val_accuracy: 0.8750\n",
      "Epoch 91/10000\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1895 - accuracy: 0.9573 - val_loss: 0.3838 - val_accuracy: 0.8750\n",
      "Epoch 92/10000\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 0.1847 - accuracy: 0.9587 - val_loss: 0.3816 - val_accuracy: 0.8778\n",
      "Epoch 93/10000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.1798 - accuracy: 0.9609 - val_loss: 0.3798 - val_accuracy: 0.8778\n",
      "Epoch 94/10000\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.1751 - accuracy: 0.9616 - val_loss: 0.3782 - val_accuracy: 0.8778\n",
      "Epoch 95/10000\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1706 - accuracy: 0.9623 - val_loss: 0.3768 - val_accuracy: 0.8778\n",
      "Epoch 96/10000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.1661 - accuracy: 0.9644 - val_loss: 0.3754 - val_accuracy: 0.8778\n",
      "Epoch 97/10000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.1617 - accuracy: 0.9666 - val_loss: 0.3738 - val_accuracy: 0.8778\n",
      "Epoch 98/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.1574 - accuracy: 0.9680 - val_loss: 0.3719 - val_accuracy: 0.8750\n",
      "Epoch 99/10000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.1532 - accuracy: 0.9680 - val_loss: 0.3696 - val_accuracy: 0.8750\n",
      "Epoch 100/10000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.1493 - accuracy: 0.9694 - val_loss: 0.3674 - val_accuracy: 0.8778\n",
      "Epoch 101/10000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.1454 - accuracy: 0.9694 - val_loss: 0.3657 - val_accuracy: 0.8807\n",
      "Epoch 102/10000\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.1417 - accuracy: 0.9723 - val_loss: 0.3648 - val_accuracy: 0.8778\n",
      "Epoch 103/10000\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 0.1381 - accuracy: 0.9730 - val_loss: 0.3643 - val_accuracy: 0.8778\n",
      "Epoch 104/10000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.1346 - accuracy: 0.9751 - val_loss: 0.3637 - val_accuracy: 0.8807\n",
      "Epoch 105/10000\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.1313 - accuracy: 0.9772 - val_loss: 0.3629 - val_accuracy: 0.8835\n",
      "Epoch 106/10000\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.1279 - accuracy: 0.9794 - val_loss: 0.3619 - val_accuracy: 0.8835\n",
      "Epoch 107/10000\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.1246 - accuracy: 0.9794 - val_loss: 0.3610 - val_accuracy: 0.8807\n",
      "Epoch 108/10000\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.1214 - accuracy: 0.9794 - val_loss: 0.3607 - val_accuracy: 0.8807\n",
      "Epoch 109/10000\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.1183 - accuracy: 0.9794 - val_loss: 0.3606 - val_accuracy: 0.8807\n",
      "Epoch 110/10000\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.1153 - accuracy: 0.9808 - val_loss: 0.3605 - val_accuracy: 0.8807\n",
      "Epoch 111/10000\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.1123 - accuracy: 0.9808 - val_loss: 0.3601 - val_accuracy: 0.8807\n",
      "Epoch 112/10000\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.1094 - accuracy: 0.9822 - val_loss: 0.3594 - val_accuracy: 0.8778\n",
      "Epoch 113/10000\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.1066 - accuracy: 0.9836 - val_loss: 0.3586 - val_accuracy: 0.8778\n",
      "Epoch 114/10000\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.1038 - accuracy: 0.9844 - val_loss: 0.3578 - val_accuracy: 0.8778\n",
      "Epoch 115/10000\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.1010 - accuracy: 0.9844 - val_loss: 0.3570 - val_accuracy: 0.8778\n",
      "Epoch 116/10000\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0983 - accuracy: 0.9851 - val_loss: 0.3563 - val_accuracy: 0.8778\n",
      "Epoch 117/10000\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0957 - accuracy: 0.9865 - val_loss: 0.3556 - val_accuracy: 0.8807\n",
      "Epoch 118/10000\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.0931 - accuracy: 0.9872 - val_loss: 0.3552 - val_accuracy: 0.8750\n",
      "Epoch 119/10000\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0907 - accuracy: 0.9872 - val_loss: 0.3550 - val_accuracy: 0.8750\n",
      "Epoch 120/10000\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.0883 - accuracy: 0.9872 - val_loss: 0.3546 - val_accuracy: 0.8750\n",
      "Epoch 121/10000\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0859 - accuracy: 0.9872 - val_loss: 0.3542 - val_accuracy: 0.8750\n",
      "Epoch 122/10000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0837 - accuracy: 0.9872 - val_loss: 0.3538 - val_accuracy: 0.8750\n",
      "Epoch 123/10000\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0815 - accuracy: 0.9879 - val_loss: 0.3531 - val_accuracy: 0.8750\n",
      "Epoch 124/10000\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0793 - accuracy: 0.9879 - val_loss: 0.3523 - val_accuracy: 0.8750\n",
      "Epoch 125/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0773 - accuracy: 0.9879 - val_loss: 0.3516 - val_accuracy: 0.8750\n",
      "Epoch 126/10000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0753 - accuracy: 0.9879 - val_loss: 0.3516 - val_accuracy: 0.8750\n",
      "Epoch 127/10000\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.0733 - accuracy: 0.9886 - val_loss: 0.3520 - val_accuracy: 0.8722\n",
      "Epoch 128/10000\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.0715 - accuracy: 0.9893 - val_loss: 0.3521 - val_accuracy: 0.8722\n",
      "Epoch 129/10000\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.0696 - accuracy: 0.9893 - val_loss: 0.3519 - val_accuracy: 0.8722\n",
      "Epoch 130/10000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0679 - accuracy: 0.9900 - val_loss: 0.3516 - val_accuracy: 0.8750\n",
      "Epoch 131/10000\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0662 - accuracy: 0.9900 - val_loss: 0.3513 - val_accuracy: 0.8722\n",
      "Epoch 132/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0645 - accuracy: 0.9900 - val_loss: 0.3510 - val_accuracy: 0.8750\n",
      "Epoch 133/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0629 - accuracy: 0.9915 - val_loss: 0.3508 - val_accuracy: 0.8750\n",
      "Epoch 134/10000\n",
      "1/1 [==============================] - 0s 276ms/step - loss: 0.0613 - accuracy: 0.9915 - val_loss: 0.3506 - val_accuracy: 0.8750\n",
      "Epoch 135/10000\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.0598 - accuracy: 0.9922 - val_loss: 0.3507 - val_accuracy: 0.8750\n",
      "Epoch 136/10000\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 0.0583 - accuracy: 0.9929 - val_loss: 0.3512 - val_accuracy: 0.8750\n",
      "Epoch 137/10000\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.0569 - accuracy: 0.9936 - val_loss: 0.3518 - val_accuracy: 0.8750\n",
      "Epoch 138/10000\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 0.0555 - accuracy: 0.9936 - val_loss: 0.3524 - val_accuracy: 0.8750\n",
      "Epoch 139/10000\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.0541 - accuracy: 0.9936 - val_loss: 0.3529 - val_accuracy: 0.8750\n",
      "Epoch 140/10000\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0528 - accuracy: 0.9936 - val_loss: 0.3532 - val_accuracy: 0.8750\n",
      "Epoch 141/10000\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0515 - accuracy: 0.9936 - val_loss: 0.3537 - val_accuracy: 0.8750\n",
      "Epoch 142/10000\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.0503 - accuracy: 0.9936 - val_loss: 0.3543 - val_accuracy: 0.8750\n",
      "Epoch 143/10000\n",
      "1/1 [==============================] - 0s 317ms/step - loss: 0.0491 - accuracy: 0.9936 - val_loss: 0.3549 - val_accuracy: 0.8750\n",
      "Epoch 144/10000\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0479 - accuracy: 0.9943 - val_loss: 0.3553 - val_accuracy: 0.8750\n",
      "Epoch 145/10000\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0467 - accuracy: 0.9943 - val_loss: 0.3555 - val_accuracy: 0.8778\n",
      "Epoch 146/10000\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0456 - accuracy: 0.9950 - val_loss: 0.3554 - val_accuracy: 0.8778\n",
      "Epoch 147/10000\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.0445 - accuracy: 0.9950 - val_loss: 0.3551 - val_accuracy: 0.8778\n",
      "Epoch 148/10000\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0435 - accuracy: 0.9957 - val_loss: 0.3547 - val_accuracy: 0.8807\n",
      "Epoch 149/10000\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.0424 - accuracy: 0.9957 - val_loss: 0.3545 - val_accuracy: 0.8807\n",
      "Epoch 150/10000\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 0.0414 - accuracy: 0.9964 - val_loss: 0.3545 - val_accuracy: 0.8807\n",
      "Epoch 151/10000\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 0.0405 - accuracy: 0.9964 - val_loss: 0.3548 - val_accuracy: 0.8807\n",
      "Epoch 152/10000\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0395 - accuracy: 0.9972 - val_loss: 0.3552 - val_accuracy: 0.8835\n",
      "Epoch 153/10000\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.0386 - accuracy: 0.9979 - val_loss: 0.3556 - val_accuracy: 0.8807\n",
      "Epoch 154/10000\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0377 - accuracy: 0.9979 - val_loss: 0.3558 - val_accuracy: 0.8807\n",
      "epochs: 154, acc: 0.9978662729263306\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/Q1/test.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/Q1/test.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.8821\n",
      "Test loss =  0.38450300693511963\n",
      "Test accuracy =  0.8820861577987671\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(64, batch_input_shape=(None,None,39)),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "adam_optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam_optimizer, metrics=['accuracy']) \n",
    "# Train the model\n",
    "my_callbacks = [ EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=20),    TensorBoard(log_dir=f'./logdir/Q1/test')]\n",
    "model_fit = model.fit(train_tensor, z_train_onehot, validation_data=(val_tensor, z_val_onehot), batch_size=len(train), epochs=10000, verbose=1, validation_split=0.0,callbacks=my_callbacks, shuffle=False, validation_batch_size=None)\n",
    "\n",
    "hist_metric = 'accuracy'\n",
    "print(f'epochs: {len(model_fit.history[hist_metric])}, acc: {model_fit.history[hist_metric][-1]}\\n')\n",
    "model.save(f'models/Q1/test.tf')\n",
    "\n",
    "loss, accuracy = model.evaluate(test_tensor,z_test_onehot)\n",
    "\n",
    "print(\"Test loss = \", loss)\n",
    "print(\"Test accuracy = \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
